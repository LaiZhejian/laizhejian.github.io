---
title: "Making Mathematical Reasoning Adaptive"
collection: publications
category: preprint
permalink: /publication/2025-09-AdaR
excerpt: 'Mathematical reasoning is a primary indicator of large language models (LLMs) intelligence. However, existing LLMs exhibit failures of robustness and generalization. This paper attributes these deficiencies to spurious reasoning, i.e., producing answers from superficial features. To address this challenge, we propose the AdaR framework to enable adaptive reasoning, wherein models rely on problem-solving logic to produce answers. AdaR synthesizes logically equivalent queries by varying variable values, and trains models with RLVR on these data to penalize spurious logic while encouraging adaptive logic. To improve data quality, we extract the problem-solving logic from the original query and generate the corresponding answer by code execution, then apply a sanity check. Experimental results demonstrate that AdaR improves robustness and generalization, achieving substantial improvement in mathematical reasoning while maintaining high data efficiency. Analysis indicates that data synthesis and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs. Subsequent analyses derive key design insights into the effect of critical factors and the applicability to instruct LLMs.'
date: 2025-09-25
venue: 'Preprint'
paperurl: 'https://arxiv.org/pdf/2510.04617'
bibtexurl: '/files/2025-09-AdaR.bib'
citation: 'Zhejian Lai, Xiang Geng, Zhijun Wang, Yang Bai, Jiahuan Li, Rongxiang Weng, Jingang Wang, Xuezhi Cao, Xunliang Cai and Shujian Huang. 2025. Making Mathematical Reasoning Adaptive <i>arXiv preprint arXiv:2510.04617</i>.'
---

<p align="center">
  <a href="https://github.com/NJUNLP/AdaR"> âš™ï¸ Code</a> | 
  <a href="https://huggingface.co/collections/DreamW1ngs/adar-68e648e59b2c9aec1208b5ef"> ğŸ¤– Project</a>
</p>

## ğŸŒ± Overview

Large Language Models (LLMs) have shown impressive reasoning capabilities, yet they often rely on **spurious reasoning** â€” producing answers from superficial features, leading to failure at robustness and generalization.

We propose **AdaR** framework to enable adaptive reasoning, wherein models rely on problem-solving logic to produce answers. **AdaR** synthesizes logically equivalent queries by varying variable values, and trains models with RLVR on these data to penalize spurious logic while encouraging adaptive logic.

The framework integrates *data synthesis* and *RLVR training* to enhance both **robustness (in-domain)** and **generalization (out-of-domain)**.

![AdaR Process Framework](/images/2025-09-AdaR/process.png)

> **Figure 1.**  
> *Subfigure I:* Three reasoning modes â€” direct inference (black), spurious reasoning (red), adaptive reasoning (green).  
> *Subfigure II:* Logic-preserving variable perturbation and gold-answer generation via executable logic.  
> *Subfigure III:* RLVR optimization encouraging adaptive reasoning through comparative feedback.

## ğŸ“ˆ Highlights

- ğŸš€ **+8.5 Average Improvement** across in-domain robustness tasks and out-of-domain tasks.
- ğŸ§® **Only 9K synthetic data** needed for significant gains.
- âš–ï¸ **Enable algebraic thinking** and improved stability under scaling.
- ğŸ” **Generalizable framework** applicable to instruct models.
